{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessory libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LUnQV3J70UAt"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder , OneHotEncoder\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/seaborn/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelational\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/seaborn/relational.py:17\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_oldcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     VectorPlotter,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     locator_to_legend_entries,\n\u001b[1;32m     13\u001b[0m     adjust_legend_subtitles,\n\u001b[1;32m     14\u001b[0m     _default_color,\n\u001b[1;32m     15\u001b[0m     _deprecate_ci,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_statistics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EstimateAggregator\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FacetGrid, _facet_docs\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstrings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocstringComponents, _core_docs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/seaborn/_statistics.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gaussian_kde\n\u001b[1;32m     32\u001b[0m     _no_scipy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/stats/__init__.py:485\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m \n\u001b[1;32m    481\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 485\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/stats/_stats_py.py:46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_mstats_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[1;32m     49\u001b[0m                                    siegelslopes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/stats/distributions.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distn_infrastructure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_continuous_distns\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_levy_stable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m levy_stable\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/stats/_discrete_distns.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entr, logsumexp, betaln, gammaln \u001b[38;5;28;01mas\u001b[39;00m gamln, zeta\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _lazywhere, rng_integers\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interp1d\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m floor, ceil, log, exp, sqrt, log1p, expm1, tanh, cosh, sinh\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/interpolate/__init__.py:167\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m========================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mInterpolation (:mod:`scipy.interpolate`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m(should not be used in new code).\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interpolate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fitpack_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# New interface to fitpack library:\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/interpolate/_interpolate.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ppoly\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fitpack2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RectBivariateSpline\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpnd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ndim_coords_from_arrays\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bsplines\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_interp_spline, BSpline\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlagrange\u001b[39m(x, w):\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import ElasticNetCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Bhr9qbLe1bED",
    "outputId": "09fef22e-022f-4dae-833f-f7041cf66ca4"
   },
   "outputs": [],
   "source": [
    "# Read the CSV file \"insurance.csv\" \n",
    "data = pd.read_csv(\"insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column and print the sum of missing values\n",
    "(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in the 'sex' column\n",
    "(data['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in the 'smoker' column\n",
    "(data['smoker'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in the 'region' column\n",
    "data['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in the 'sex' column and plot a bar chart\n",
    "data['sex'].value_counts().plot(kind='bar', figsize=(8, 5))\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Sex')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in the 'smoker' column and plot a bar chart\n",
    "data['smoker'].value_counts().plot(kind='bar', figsize=(8, 5))\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Smoker')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Smokers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each unique value in the 'region' column and plot a bar chart\n",
    "data['region'].value_counts().plot(kind='bar', figsize=(8, 5))\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Regions')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['children'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepropcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a sample dataframe with categorical data\n",
    "sexx = pd.DataFrame({'sex': ['male', 'female']})\n",
    "smokerr = pd.DataFrame({'smoker': ['no', 'yes']})\n",
    "regionn = pd.DataFrame({'region': ['southeast', 'southwest','northeast',' northwest']})\n",
    "\n",
    "print(f\"Before Encoding the Data:\\n\\n{sexx}\\n\")\n",
    "print(f\"Before Encoding the Data:\\n\\n{smokerr}\\n\")\n",
    "print(f\"Before Encoding the Data:\\n\\n{regionn}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xoq0fM5R1zMU"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a LabelEncoder object\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encode the categorical  column\n",
    "data['sex'] = encoder.fit_transform(data['sex'])\n",
    "data['smoker'] = encoder.fit_transform(data['smoker'])\n",
    "data['region'] = encoder.fit_transform(data['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JY1jrL-2Q5e"
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize BMI\n",
    "def categorize_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'Underweight'\n",
    "    elif 18.5 <= bmi < 25:\n",
    "        return 'Normal'\n",
    "    elif 25 <= bmi < 30:\n",
    "        return 'Overweight'\n",
    "    else:\n",
    "        return 'Obesity'\n",
    "\n",
    "# Apply the function to the 'bmi' column and create a new column 'BMI_category'\n",
    "data['BMI_category'] = data['bmi'].apply(categorize_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BMI_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the categorical values in 'BMI_category' to numerical values\n",
    "data['BMI_category'] = data['BMI_category'].map({'Obesity': 1, 'Overweight': 2, 'Normal': 3, 'Underweight': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 95th percentile as the upper limit\n",
    "upper_limit = data['bmi'].quantile(0.95)\n",
    "\n",
    "# Calculate the 5th percentile as the lower limit\n",
    "lower_limit = data['bmi'].quantile(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the condition to the 'bmi' column and replace values outside the limits\n",
    "data['bmi'] = np.where(data['bmi'] >= upper_limit, upper_limit,\n",
    "                       np.where(data['bmi'] <= lower_limit, lower_limit, data['bmi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Dataset and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (x) and target variable (y)\n",
    "x = data.drop(columns=['charges'])  # Features\n",
    "y = data['charges']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_regression, k=7).fit(x,y)\n",
    "\n",
    "# Get the boolean mask indicating selected features\n",
    "features_mask = selector.get_support()\n",
    "\n",
    "# Get the names of the selected features\n",
    "features = x.columns[features_mask]\n",
    "\n",
    "# Sort the DataFrame by importance in ascending order\n",
    "pd.DataFrame({ 'Feature_name': features, 'Importance': selector.scores_[features_mask]}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop the 'region' column as it has the less feature importance\n",
    "x = x.drop(columns=['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngg9tida3OC_"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test, y_train , y_test = train_test_split( x ,y , test_size = 0.2 , random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMCNY8a932ow"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Create a Random Forest Regressor model\n",
    "model = RandomForestRegressor(n_estimators=100, bootstrap=True, max_depth=4)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xuUrIDuX4q_G",
    "outputId": "6018bfb7-ae32-4e38-bd12-c43d3c750842"
   },
   "outputs": [],
   "source": [
    "# testing the model on test data\n",
    "predicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUU-deNT4rdy",
    "outputId": "704f4ffa-37d7-48bf-e4d6-83ed2d3e14b2"
   },
   "outputs": [],
   "source": [
    "# Scores of Model\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mean_absolute_percentage_error(predicted , y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CxHBwJ75nN5",
    "outputId": "479f05c1-32fb-4577-afac-ef73c1c129c6"
   },
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"Accuracy : \" , r2_score(predicted , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lqy8_jA1Ay-5",
    "outputId": "3a96d9d1-86b5-4344-ad8f-84cbfbd2e7a1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training Cross Validation model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model , x_train ,y_train ,cv = 10)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth' : [2,4,6,8,10],\n",
    "    'max_samples': [0.1,0.3,0.6,1.0],\n",
    "            \n",
    "    }\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSearchCV object\n",
    "model_search = GridSearchCV(model, parameters, cv=10, n_jobs=-1)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "model_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the best parameters found by GridSearchCV\n",
    "best_params = model_search.best_params_\n",
    "print(best_params)\n",
    "# Access the best score achieved by GridSearchCV\n",
    "best_score = model_search.best_score_\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_search.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(pred , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Gradient Boosting Regressor model (hyperparameters can be tuned later)\n",
    "model1 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.8, max_depth=2)\n",
    "\n",
    "# Train the model on the training data (x_train, y_train)\n",
    "model1.fit(x_train, y_train)\n",
    "\n",
    "# Predict target values for the test data (x_test)\n",
    "y_pred = model1.predict(x_test)\n",
    "\n",
    "model1.score(x_train, y_train),r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Another Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Create a K-Nearest Neighbors Regressor model\n",
    "neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "# Train the KNN model on the training data\n",
    "neigh.fit(x_train, y_train)\n",
    "\n",
    "y_pred2 = model.predict(x_test)\n",
    "neigh.score(x_train, y_train),r2_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# Create a Kernel Ridge Regression model\n",
    "krr = KernelRidge(alpha=1.0)  # Adjust alpha for regularization\n",
    "\n",
    "# Train the KRR model on the training data\n",
    "krr.fit(x_train, y_train)\n",
    "\n",
    "# Predict target values for the test data using the KRR model\n",
    "y_pred3 = krr.predict(x_test)\n",
    "\n",
    "krr.score(x_train, y_train),r2_score(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model which has the maximum scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model using the pickle module to the working directory\n",
    "pickle.dump(model1 , open('med_model2.pkl' , \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
